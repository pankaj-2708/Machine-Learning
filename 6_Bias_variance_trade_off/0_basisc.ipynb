{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3442e77e-a43f-4f1f-9f3c-786cc6418c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "In machine learning, bias refers to a systematic error or prejudice in the model's predictions due to incorrect assumptions or \n",
    "flawed training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fc99ea-6ff3-463f-9e54-dea5e23f56c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "The bias-variance trade-off is a fundamental concept in machine learning and statistics that describes the tension between two \n",
    "sources of error when building predictive models: bias and variance. Managing this trade-off is crucial for building models that \n",
    "generalize well to unseen data.\n",
    "\n",
    "\n",
    "| Term                  | Meaning                                                                                                   |\n",
    "| --------------------- | --------------------------------------------------------------------------------------------------------- |\n",
    "| **Bias**              | Error from incorrect assumptions in the learning algorithm. High bias leads to **underfitting**.          |\n",
    "| **Variance**          | Error from sensitivity to small fluctuations in the training set. High variance leads to **overfitting**. |\n",
    "| **Irreducible Error** | Noise in the data that can't be eliminated by any model.  |\n",
    "\n",
    "\n",
    "visualisation\n",
    "\n",
    "Error\n",
    "â”‚           BiasÂ²\n",
    "â”‚           â•­â”€â”€â”€â”€â•®\n",
    "â”‚          â•­â•¯    â•°â”€â”€â”€â”€â”€â”€â”€â•®\n",
    "â”‚      â•­â”€â”€â”€â•¯             â•°â”€â”€â•® Variance\n",
    "â”‚â”€â”€â”€â”€â”€â•¯                     â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Model Complexity\n",
    "                 â†‘\n",
    "           Optimal point\n",
    "\n",
    "\n",
    "âš–ï¸ The Trade-off\n",
    "\n",
    "    High Bias (Low Complexity):\n",
    "\n",
    "        Simple models (e.g., linear regression on nonlinear data).\n",
    "\n",
    "        Can't capture patterns â†’ high training and test error.\n",
    "\n",
    "    High Variance (High Complexity):\n",
    "\n",
    "        Complex models (e.g., deep decision trees or high-degree polynomials).\n",
    "\n",
    "        Memorize training data â†’ low training error but high test error.\n",
    "\n",
    "\n",
    "ğŸ“š Example\n",
    "                        \n",
    "Suppose you're doing polynomial regression:\n",
    "\n",
    "Degree 1 â†’ High bias, low variance (underfit).\n",
    "\n",
    "Degree 15 â†’ Low bias, high variance (overfit).\n",
    "\n",
    "Degree 3â€“5 â†’ Balanced trade-off.\n",
    "\n",
    "\n",
    "\n",
    "| Approach             | Action                                               |\n",
    "| -------------------- | ---------------------------------------------------- |\n",
    "| **Regularization**   | Penalizes complexity (e.g., L1/L2 in linear models). |\n",
    "| **Bagging **         | Train multiple models independently on different random subsets of data, then aggregate their predictions.|\n",
    "| **Boosting**         | Train models sequentially, each one learning from the errors of the previous.|\n",
    "| **Early stopping**   | Stops training before overfitting starts.            |\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
